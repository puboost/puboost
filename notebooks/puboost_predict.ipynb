{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c84ab51-0a23-47aa-8622-fe8a6c654b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d7e2f82-7a1d-4aeb-a876-2f0f35cfc6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PUBoostClassifier():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description\n",
    "        '''\n",
    "        self.model_list = []\n",
    "        \n",
    "    def fit(self, X_seed, X_poblacion, random_state, T=50, clf='logistic', \n",
    "            l1=1, l2=1, e1=1, e2=1, **kwargs_clf):\n",
    "        \"\"\"\n",
    "        Returns avg of oob predictions of classifier para la poblacion\n",
    "        Param:\n",
    "            - T number of baggint iteractions \n",
    "            - clf: base estimator (one of rg, logistic)\n",
    "        \"\"\"\n",
    "        self.T = T\n",
    "        \n",
    "        # K: size of boostrap sample (= size of seed)\n",
    "        K = X_seed.shape[0]\n",
    "        # U: size of poblation\n",
    "        U = X_poblacion.shape[0]\n",
    "        # se entrena con una muestra balanceada\n",
    "        # vector target: primero seed - luego poblacion\n",
    "        y_poblacion = np.zeros(U)\n",
    "        # y_train = np.concatenate([np.ones(K), np.zeros(K)])\n",
    "        # initialize numerador de predicciones\n",
    "        pred = np.zeros(U)\n",
    "        # initialize denominador de predicciones\n",
    "        n = np.zeros(U)\n",
    "        # iniialize weight vectors\n",
    "        w_poblacion = np.ones(U)\n",
    "        w_seed = np.ones(K)\n",
    "\n",
    "        # bagging\n",
    "        for t in range(T):\n",
    "            # get sample\n",
    "            idx_train = np.random.choice(U, K, replace=True)\n",
    "            X_train = np.concatenate([X_seed, X_poblacion.iloc[idx_train,:]])\n",
    "            # y_train vector\n",
    "            y_train = np.concatenate([np.ones(K), y_poblacion[idx_train]])\n",
    "            # weights\n",
    "            # print(w_poblacion[idx_train], \"/n\")\n",
    "            weights = np.concatenate([w_seed, w_poblacion[idx_train]])      \n",
    "            # train\n",
    "            if clf=='rf':\n",
    "                clf = RandomForestClassifier(**kwargs_clf)\n",
    "            if clf=='logistic':\n",
    "                clf = LogisticRegression(**kwargs_clf)\n",
    "            if clf=='tree':\n",
    "                clf = DecisionTreeClassifier(**kwargs_clf)\n",
    "            if clf=='knn':\n",
    "                clf = KNeighborsClassifier(**kwargs_clf)\n",
    "            clf.fit(X_train, y_train, sample_weight = weights)\n",
    "            \n",
    "            self.model_list.append(clf)\n",
    "            \n",
    "            # predict OOB\n",
    "            idx_oob = np.full(U, True)\n",
    "            idx_oob[idx_train] = False\n",
    "            _pred = clf.predict_proba(X_poblacion.iloc[idx_oob,:])[:,clf.classes_ == 1].ravel()\n",
    "            pred[idx_oob] += _pred\n",
    "            n[idx_oob] += 1\n",
    "            # update weight vector\n",
    "            if t > (T*l1):\n",
    "                _wupdate = np.zeros(U)\n",
    "                _wupdate[idx_oob] = _pred\n",
    "                w_poblacion += (-_wupdate/T*l2) \n",
    "            if t > (T*e1):\n",
    "                y_poblacion[(pred/n)>e2] = 1\n",
    "        scores = pred / n\n",
    "        return scores\n",
    "        \n",
    "    def predict(self, df):\n",
    "        \n",
    "        predic = np.zeros(df.shape[0])\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            _predic = self.model_list[t].predict_proba(df)[:,self.model_list[t].classes_ == 1].ravel()\n",
    "            predic += _predic\n",
    "        \n",
    "        return predic / self.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b41176ea-2f8f-4b24-b1c9-1b512874c000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "## creo dataset\n",
    "rng = np.random.RandomState(123)\n",
    "X, y = make_classification(n_samples=5000\n",
    "                       ,n_features=2\n",
    "                       ,n_informative=2\n",
    "                       ,n_redundant=0\n",
    "                       ,n_repeated=0 \n",
    "                       ,n_classes=2\n",
    "                       ,n_clusters_per_class=1\n",
    "                       ,weights=[0.80, 0.20]\n",
    "                       ,flip_y=0\n",
    "                       ,class_sep=0.4\n",
    "                       ,random_state=rng)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, size=1, palette=['#440154FF','#FDE725FF'])\n",
    "\n",
    "X_seed = X[y==1,:]\n",
    "X_poblacion = X[y==0,:]\n",
    "contamination = 0.5\n",
    "idx_hidden = rng.choice(np.argwhere(y == 1).ravel()\n",
    "                        ,size=int(X_seed.shape[0]*contamination)\n",
    "                        ,replace=False)\n",
    "y[idx_hidden]=0\n",
    "# sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, size=1, palette=['#440154FF','#FDE725FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f73ef93d-85c7-4b9e-b595-7972dd1d3e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.90704031 0.         ... 0.76203421 0.         0.83403541]\n",
      "1000\n",
      "0.9720912810150073\n",
      "4000\n",
      "0.2567882821238018\n",
      "5000\n",
      "0.3998488819020429\n"
     ]
    }
   ],
   "source": [
    "pclf='tree'\n",
    "pkwargs_clf = {'min_samples_leaf': 5}\n",
    "\n",
    "# predict bagged\n",
    "puboost_clf = PUBoostClassifier()\n",
    "\n",
    "pred_sbagged = puboost_clf.fit(X_seed = pd.DataFrame(X[y==1, :]), X_poblacion = pd.DataFrame(X[y==0, :]),\n",
    "                               random_state = 42, T=100, clf=pclf, \n",
    "                               l1=0.5, l2=0.5, e1=0.5, e2=0.5, **pkwargs_clf)\n",
    "\n",
    "print(pred_sbagged)\n",
    "# # predict poblacion\n",
    "# plt.scatter(X[y==0,0], X[y==0,1], c=pred_sbagged, cmap=cm, s=4)\n",
    "\n",
    "# # average precision\n",
    "# average_precision_score(y_true, pred_sbagged)\n",
    "\n",
    "print(len(puboost_clf.predict(X_seed)))\n",
    "print(puboost_clf.predict(X_seed).mean())\n",
    "\n",
    "print(len(puboost_clf.predict(X_poblacion)))\n",
    "print(puboost_clf.predict(X_poblacion).mean())\n",
    "\n",
    "print(len(puboost_clf.predict(X)))\n",
    "print(puboost_clf.predict(X).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
